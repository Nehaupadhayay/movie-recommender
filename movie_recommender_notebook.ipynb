{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b87448c",
   "metadata": {},
   "source": [
    "# Movie Recommender — Build & Save Notebook\n",
    "\n",
    "This notebook builds **content-based** (TF-IDF) and **collaborative** (Surprise SVD) recommenders, saves model artifacts to `/mnt/data/recommender_models/`, and demonstrates usage.\n",
    "\n",
    "**Notes before running**\n",
    "- Place `movies_metadata.csv` in `/mnt/data/` or the notebook's working directory. If you want SVD/collaborative model, also place `ratings.csv` or `ratings_small.csv` in the same folder.\n",
    "- The environment may or may not allow `pip install scikit-surprise`. If internet install fails, the notebook will still build the content-based model and skip SVD.\n",
    "- Your previously uploaded notebook is available at:\n",
    "\n",
    "```\n",
    "/mnt/data/movie-recommender-systems (1).ipynb\n",
    "```\n",
    "You can open or inspect it for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install scikit-surprise if you want collaborative SVD (internet required)\n",
    "# Uncomment if you have internet access\n",
    "# !pip install scikit-surprise joblib\n",
    "\n",
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import os, warnings, json, glob\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import joblib, pickle\n",
    "\n",
    "# Try import surprise (will be used only if available)\n",
    "try:\n",
    "    from surprise import Reader, Dataset, SVD\n",
    "    from surprise.model_selection import train_test_split\n",
    "    from surprise import accuracy\n",
    "    SURPRISE_AVAILABLE = True\n",
    "except Exception:\n",
    "    SURPRISE_AVAILABLE = False\n",
    "\n",
    "print('Surprise available:', SURPRISE_AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate movies and ratings files (search common locations)\n",
    "candidates = glob.glob('/mnt/data/**/movies*.csv', recursive=True) + glob.glob('movies*.csv') + glob.glob('/mnt/data/**/movies_metadata*.csv', recursive=True)\n",
    "movies_path = candidates[0] if candidates else None\n",
    "# Fallback common names\n",
    "for name in ['movies_metadata.csv','movies.csv','movies_metadata_clean.csv']:\n",
    "    if movies_path is None and os.path.exists(os.path.join('/mnt/data', name)):\n",
    "        movies_path = os.path.join('/mnt/data', name)\n",
    "\n",
    "ratings_candidates = glob.glob('/mnt/data/**/ratings*.csv', recursive=True) + glob.glob('ratings*.csv')\n",
    "ratings_path = ratings_candidates[0] if ratings_candidates else None\n",
    "\n",
    "print('Movies path found ->', movies_path)\n",
    "print('Ratings path found ->', ratings_path)\n",
    "if movies_path is None:\n",
    "    raise FileNotFoundError('movies metadata CSV not found. Upload movies_metadata.csv to /mnt/data or working directory before running.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4793bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies metadata robustly and prepare fields\n",
    "def load_movies(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, engine='python', on_bad_lines='skip')\n",
    "    except Exception:\n",
    "        df = pd.read_csv(path, on_bad_lines='skip', low_memory=False)\n",
    "    return df\n",
    "\n",
    "md = load_movies(movies_path)\n",
    "print('Loaded movies:', md.shape)\n",
    "\n",
    "for col in ['genres','overview','title','id','release_date']:\n",
    "    if col not in md.columns:\n",
    "        md[col] = np.nan\n",
    "\n",
    "# clean genres (expects JSON-like lists as strings)\n",
    "md['genres'] = md['genres'].fillna('[]').apply(lambda x: literal_eval(x) if isinstance(x, str) else x)\n",
    "md['genres'] = md['genres'].apply(lambda x: [d['name'] for d in x] if isinstance(x, list) else [])\n",
    "md['overview'] = md['overview'].fillna('')\n",
    "md['title'] = md['title'].fillna('')\n",
    "md['id'] = md['id'].astype(str).fillna('')\n",
    "\n",
    "# create a 'soup' of text features for content-based model\n",
    "md['soup'] = md.apply(lambda x: ' '.join(x['genres']) + ' ' + x['overview'], axis=1)\n",
    "\n",
    "# show few rows\n",
    "md[['title','release_date','genres']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TF-IDF content-based model and save artifacts\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(md['soup'].values.astype('U'))\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# mapping title -> index (handle duplicates by taking first)\n",
    "indices = pd.Series(md.index, index=md['title']).drop_duplicates()\n",
    "\n",
    "out_dir = '/mnt/data/recommender_models'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joblib.dump(tfidf, os.path.join(out_dir, 'tfidf_vectorizer.joblib'))\n",
    "joblib.dump(cosine_sim, os.path.join(out_dir, 'cosine_sim.joblib'), compress=3)\n",
    "md.to_pickle(os.path.join(out_dir, 'movies_metadata_df.pkl'))\n",
    "indices.to_pickle(os.path.join(out_dir, 'title_indices.pkl'))\n",
    "\n",
    "print('Saved content-based artifacts to', out_dir)\n",
    "print('Files:', os.listdir(out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: get content-based recommendations by title\n",
    "def get_content_recommendations(title, topn=10):\n",
    "    if title not in indices.index:\n",
    "        matches = md[md['title'].str.contains(title, case=False, na=False)]\n",
    "        if matches.shape[0] == 0:\n",
    "            return None\n",
    "        idx = matches.index[0]\n",
    "    else:\n",
    "        idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1: topn+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    results = md.iloc[movie_indices][['title','release_date','id']].copy()\n",
    "    results['score'] = [i[1] for i in sim_scores]\n",
    "    return results.reset_index(drop=True)\n",
    "\n",
    "# Demo\n",
    "sample = md['title'].dropna().iloc[0]\n",
    "print('Sample movie:', sample)\n",
    "print(get_content_recommendations(sample, topn=5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75284459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: build Surprise SVD collaborative model if ratings CSV present and surprise available\n",
    "svd_path = os.path.join(out_dir, 'svd_model.pkl')\n",
    "if SURPRISE_AVAILABLE and ratings_path is not None:\n",
    "    try:\n",
    "        ratings = pd.read_csv(ratings_path)\n",
    "    except Exception:\n",
    "        ratings = pd.read_csv(ratings_path, engine='python', on_bad_lines='skip')\n",
    "    print('Ratings loaded:', ratings.shape)\n",
    "    # try to detect columns\n",
    "    cols = [c.lower() for c in ratings.columns]\n",
    "    mapping = {}\n",
    "    mapping['user'] = ratings.columns[0]\n",
    "    mapping['item'] = ratings.columns[1] if len(ratings.columns)>1 else ratings.columns[0]\n",
    "    mapping['rating'] = ratings.columns[2] if len(ratings.columns)>2 else ratings.columns[-1]\n",
    "    ratings_ren = ratings.rename(columns={mapping['user']:'userId', mapping['item']:'movieId', mapping['rating']:'rating'})[['userId','movieId','rating']].dropna()\n",
    "    ratings_ren['userId'] = ratings_ren['userId'].astype(str)\n",
    "    ratings_ren['movieId'] = ratings_ren['movieId'].astype(str)\n",
    "    ratings_ren['rating'] = ratings_ren['rating'].astype(float)\n",
    "\n",
    "    reader = Reader(rating_scale=(ratings_ren['rating'].min(), ratings_ren['rating'].max()))\n",
    "    data = Dataset.load_from_df(ratings_ren[['userId','movieId','rating']], reader)\n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    algo = SVD(n_factors=100, n_epochs=20, random_state=42)\n",
    "    print('Training SVD (may take time)...')\n",
    "    algo.fit(trainset)\n",
    "    preds = algo.test(testset)\n",
    "    rmse = accuracy.rmse(preds, verbose=False)\n",
    "    print('SVD RMSE:', rmse)\n",
    "    with open(svd_path,'wb') as f:\n",
    "        pickle.dump(algo, f)\n",
    "    print('Saved SVD model to', svd_path)\n",
    "else:\n",
    "    print('Skipping SVD. Either Surprise not installed or ratings CSV missing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick usage examples (load saved artifacts and query)\n",
    "# Load artifacts\n",
    "import joblib, pandas as pd, pickle\n",
    "tfidf = joblib.load('/mnt/data/recommender_models/tfidf_vectorizer.joblib')\n",
    "cosine_sim = joblib.load('/mnt/data/recommender_models/cosine_sim.joblib')\n",
    "md = pd.read_pickle('/mnt/data/recommender_models/movies_metadata_df.pkl')\n",
    "indices = pd.read_pickle('/mnt/data/recommender_models/title_indices.pkl')\n",
    "\n",
    "# Example: content recommendations\n",
    "print(get_content_recommendations(sample, topn=5))\n",
    "\n",
    "# Example: SVD prediction (if saved)\n",
    "svd_path = '/mnt/data/recommender_models/svd_model.pkl'\n",
    "if os.path.exists(svd_path):\n",
    "    algo = pickle.load(open(svd_path,'rb'))\n",
    "    print('Example SVD predict:', algo.predict(uid=str(1), iid=str(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8df70",
   "metadata": {},
   "source": [
    "---\n",
    "**After running this notebook** the artifacts will be in `/mnt/data/recommender_models/`.  \n",
    "You can download them from the Files pane or via links if your environment supports it.\n",
    "\n",
    "**Uploaded notebook (for reference):** `/mnt/data/movie-recommender-systems (1).ipynb`\n",
    "\n",
    "If you want, I can now run this notebook here and produce the artifacts — upload the needed CSVs (`movies_metadata.csv` and optionally `ratings.csv`) into `/mnt/data/` and tell me to run it. Or download the notebook from the link below and run locally/Colab.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
